{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b0222b-3941-4a37-8caa-0508242804d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_diabetes\n",
    "from sklearn.metrics import f1_score, r2_score, precision_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_absolute_error, recall_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d99773b8-1bc6-4bc1-ab47-5a2a3874b7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9664818612187034\n",
      "0.9666666666666668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:    0.7s remaining:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "kn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "scoring = {\n",
    "    'f1_macro': make_scorer(f1_score, average='weighted'),\n",
    "    'recall_macro': make_scorer(recall_score, average='weighted')\n",
    "}\n",
    "start1 = time.time()\n",
    "score1 = cross_validate(kn, X, y, n_jobs = 4, verbose = 5, cv = 5, scoring = scoring, return_train_score=True)\n",
    "end1 = time.time()\n",
    "\n",
    "print(score1['test_f1_macro'].mean())\n",
    "print(score1['test_recall_macro'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f9e9a6-d3b4-4f74-ac60-0bab48d371cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9659090909090908\n",
      "0.9666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   6 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "start2 = time.time()\n",
    "score2 = cross_validate(kn, X, y, n_jobs = 4, verbose = 5, cv = 10, scoring = scoring, return_train_score=True)\n",
    "end2 = time.time()\n",
    "print(score2['test_f1_macro'].mean())\n",
    "print(score2['test_recall_macro'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b3ce6ad-e7a5-418d-9951-38f198a985aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00102544 0.00089669 0.00096846 0.00092626 0.00092411]\n",
      "0.7693085670471191\n",
      "0.0890817642211914\n",
      "Fold 1 F1 Score: 0.9665831244778613\n",
      "Fold 2 F1 Score: 0.9665831244778613\n",
      "Fold 3 F1 Score: 0.9326599326599326\n",
      "Fold 4 F1 Score: 0.9665831244778613\n",
      "Fold 5 F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(score1['fit_time']) #czy to nie jest czas trenowania modelu? Uśrednić to?\n",
    "train_timeS1 = end1 - start1\n",
    "train_timeS2 = end2 - start2\n",
    "print(train_timeS1)\n",
    "print(train_timeS2)\n",
    "\n",
    "for i, f1 in enumerate(score1['test_f1_macro'], 1):\n",
    "    print(f\"Fold {i} F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d52abae-12ab-4870-a3e6-e146c5d9d4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  f1_macro: (train=0.967, test=0.967) recall_macro: (train=0.967, test=0.967) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.956, test=1.000) recall_macro: (train=0.956, test=1.000) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.956, test=1.000) recall_macro: (train=0.956, test=1.000) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.958, test=0.967) recall_macro: (train=0.958, test=0.967) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.950, test=1.000) recall_macro: (train=0.950, test=1.000) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.956, test=1.000) recall_macro: (train=0.956, test=1.000) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.956, test=1.000) recall_macro: (train=0.956, test=1.000) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.958, test=0.967) recall_macro: (train=0.958, test=0.967) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.963, test=0.933) recall_macro: (train=0.963, test=0.933) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.970, test=0.933) recall_macro: (train=0.970, test=0.933) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.956, test=1.000) recall_macro: (train=0.956, test=1.000) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.967, test=0.933) recall_macro: (train=0.967, test=0.933) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.963, test=0.933) recall_macro: (train=0.963, test=0.933) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.978, test=0.861) recall_macro: (train=0.978, test=0.867) total time=   0.0s\n",
      "[CV] END  f1_macro: (train=0.956, test=1.000) recall_macro: (train=0.956, test=1.000) total time=   0.0s\n",
      "Fitting 5 folds for each of 175 candidates, totalling 875 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciejrudy/conda/envs/pandas130/lib/python3.9/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9557569893635829"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "scoring2 = {\n",
    "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "    'precision_macro': make_scorer(precision_score, average='macro', zero_division=0)\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "parameters = {\n",
    "    'max_depth': [1, 2, 4, 8, 16, 32, 64],\n",
    "    'n_estimators': list(range(1, 26))\n",
    "}\n",
    "\n",
    "start3 = time.time()\n",
    "mod = GridSearchCV(rf, parameters, cv = 5, scoring = scoring2, refit='precision_macro', verbose = 1, n_jobs = -1)\n",
    "mod.fit(X,y)\n",
    "end3 = time.time()\n",
    "cv_results = mod.cv_results_\n",
    "\n",
    "\n",
    "cv_results['mean_test_f1_macro'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f71dcb6-512d-481c-8a3d-a366c59dc5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores for each parameter combination:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor params, f1 in zip(cv_results[\\'params\\'], cv_results[\\'mean_test_f1_macro\\']):\\n    print(f\"Params: {params}, F1 Score: {f1}\")\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"F1 Scores for each parameter combination:\")\n",
    "'''\n",
    "for params, f1 in zip(cv_results['params'], cv_results['mean_test_f1_macro']):\n",
    "    print(f\"Params: {params}, F1 Score: {f1}\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1988abd-5ec0-4b7e-a5da-9857a912a053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9596944017863965\n",
      "Precision score for each parameter combination:\n",
      "Params: {'max_depth': 1, 'n_estimators': 1}, F1 Score: 0.47799802536644637\n",
      "Params: {'max_depth': 1, 'n_estimators': 2}, F1 Score: 0.7648574335880838\n",
      "Params: {'max_depth': 1, 'n_estimators': 3}, F1 Score: 0.9724941724941726\n",
      "Params: {'max_depth': 1, 'n_estimators': 4}, F1 Score: 0.9724941724941726\n",
      "Params: {'max_depth': 1, 'n_estimators': 5}, F1 Score: 0.9632996632996633\n",
      "Params: {'max_depth': 1, 'n_estimators': 6}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 1, 'n_estimators': 7}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 1, 'n_estimators': 8}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 1, 'n_estimators': 9}, F1 Score: 0.946868686868687\n",
      "Params: {'max_depth': 1, 'n_estimators': 10}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 1, 'n_estimators': 11}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 1, 'n_estimators': 12}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 1, 'n_estimators': 13}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 1, 'n_estimators': 14}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 1, 'n_estimators': 15}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 1, 'n_estimators': 16}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 1, 'n_estimators': 17}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 1, 'n_estimators': 18}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 1, 'n_estimators': 19}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 1, 'n_estimators': 20}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 1, 'n_estimators': 21}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 1, 'n_estimators': 22}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 1, 'n_estimators': 23}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 1, 'n_estimators': 24}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 1, 'n_estimators': 25}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 2, 'n_estimators': 1}, F1 Score: 0.9590261590261591\n",
      "Params: {'max_depth': 2, 'n_estimators': 2}, F1 Score: 0.9610774410774411\n",
      "Params: {'max_depth': 2, 'n_estimators': 3}, F1 Score: 0.9632996632996633\n",
      "Params: {'max_depth': 2, 'n_estimators': 4}, F1 Score: 0.9632996632996633\n",
      "Params: {'max_depth': 2, 'n_estimators': 5}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 6}, F1 Score: 0.94996632996633\n",
      "Params: {'max_depth': 2, 'n_estimators': 7}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 8}, F1 Score: 0.94996632996633\n",
      "Params: {'max_depth': 2, 'n_estimators': 9}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 10}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 11}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 12}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 13}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 14}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 15}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 16}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 17}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 18}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 19}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 2, 'n_estimators': 20}, F1 Score: 0.9656565656565658\n",
      "Params: {'max_depth': 2, 'n_estimators': 21}, F1 Score: 0.9656565656565658\n",
      "Params: {'max_depth': 2, 'n_estimators': 22}, F1 Score: 0.9583838383838383\n",
      "Params: {'max_depth': 2, 'n_estimators': 23}, F1 Score: 0.9583838383838383\n",
      "Params: {'max_depth': 2, 'n_estimators': 24}, F1 Score: 0.9583838383838383\n",
      "Params: {'max_depth': 2, 'n_estimators': 25}, F1 Score: 0.94996632996633\n",
      "Params: {'max_depth': 4, 'n_estimators': 1}, F1 Score: 0.9578282828282829\n",
      "Params: {'max_depth': 4, 'n_estimators': 2}, F1 Score: 0.9501010101010102\n",
      "Params: {'max_depth': 4, 'n_estimators': 3}, F1 Score: 0.9724941724941726\n",
      "Params: {'max_depth': 4, 'n_estimators': 4}, F1 Score: 0.9568181818181818\n",
      "Params: {'max_depth': 4, 'n_estimators': 5}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 4, 'n_estimators': 6}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 4, 'n_estimators': 7}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 4, 'n_estimators': 8}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 4, 'n_estimators': 9}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 4, 'n_estimators': 10}, F1 Score: 0.9550168350168349\n",
      "Params: {'max_depth': 4, 'n_estimators': 11}, F1 Score: 0.9550168350168349\n",
      "Params: {'max_depth': 4, 'n_estimators': 12}, F1 Score: 0.9550168350168349\n",
      "Params: {'max_depth': 4, 'n_estimators': 13}, F1 Score: 0.9550168350168349\n",
      "Params: {'max_depth': 4, 'n_estimators': 14}, F1 Score: 0.9550168350168349\n",
      "Params: {'max_depth': 4, 'n_estimators': 15}, F1 Score: 0.9550168350168349\n",
      "Params: {'max_depth': 4, 'n_estimators': 16}, F1 Score: 0.9550168350168349\n",
      "Params: {'max_depth': 4, 'n_estimators': 17}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 4, 'n_estimators': 18}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 4, 'n_estimators': 19}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 4, 'n_estimators': 20}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 4, 'n_estimators': 21}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 4, 'n_estimators': 22}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 4, 'n_estimators': 23}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 4, 'n_estimators': 24}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 4, 'n_estimators': 25}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 8, 'n_estimators': 1}, F1 Score: 0.9578282828282829\n",
      "Params: {'max_depth': 8, 'n_estimators': 2}, F1 Score: 0.9501010101010102\n",
      "Params: {'max_depth': 8, 'n_estimators': 3}, F1 Score: 0.9674436674436674\n",
      "Params: {'max_depth': 8, 'n_estimators': 4}, F1 Score: 0.9517676767676768\n",
      "Params: {'max_depth': 8, 'n_estimators': 5}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 8, 'n_estimators': 6}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 8, 'n_estimators': 7}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 8, 'n_estimators': 8}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 8, 'n_estimators': 9}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 8, 'n_estimators': 10}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 8, 'n_estimators': 11}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 8, 'n_estimators': 12}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 8, 'n_estimators': 13}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 8, 'n_estimators': 14}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 8, 'n_estimators': 15}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 8, 'n_estimators': 16}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 8, 'n_estimators': 17}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 8, 'n_estimators': 18}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 8, 'n_estimators': 19}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 8, 'n_estimators': 20}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 8, 'n_estimators': 21}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 8, 'n_estimators': 22}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 8, 'n_estimators': 23}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 8, 'n_estimators': 24}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 8, 'n_estimators': 25}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 16, 'n_estimators': 1}, F1 Score: 0.9578282828282829\n",
      "Params: {'max_depth': 16, 'n_estimators': 2}, F1 Score: 0.9501010101010102\n",
      "Params: {'max_depth': 16, 'n_estimators': 3}, F1 Score: 0.9674436674436674\n",
      "Params: {'max_depth': 16, 'n_estimators': 4}, F1 Score: 0.9517676767676768\n",
      "Params: {'max_depth': 16, 'n_estimators': 5}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 16, 'n_estimators': 6}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 16, 'n_estimators': 7}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 16, 'n_estimators': 8}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 16, 'n_estimators': 9}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 16, 'n_estimators': 10}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 16, 'n_estimators': 11}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 16, 'n_estimators': 12}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 16, 'n_estimators': 13}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 16, 'n_estimators': 14}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 16, 'n_estimators': 15}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 16, 'n_estimators': 16}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 16, 'n_estimators': 17}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 16, 'n_estimators': 18}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 16, 'n_estimators': 19}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 16, 'n_estimators': 20}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 16, 'n_estimators': 21}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 16, 'n_estimators': 22}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 16, 'n_estimators': 23}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 16, 'n_estimators': 24}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 16, 'n_estimators': 25}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 32, 'n_estimators': 1}, F1 Score: 0.9578282828282829\n",
      "Params: {'max_depth': 32, 'n_estimators': 2}, F1 Score: 0.9501010101010102\n",
      "Params: {'max_depth': 32, 'n_estimators': 3}, F1 Score: 0.9674436674436674\n",
      "Params: {'max_depth': 32, 'n_estimators': 4}, F1 Score: 0.9517676767676768\n",
      "Params: {'max_depth': 32, 'n_estimators': 5}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 32, 'n_estimators': 6}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 32, 'n_estimators': 7}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 32, 'n_estimators': 8}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 32, 'n_estimators': 9}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 32, 'n_estimators': 10}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 32, 'n_estimators': 11}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 32, 'n_estimators': 12}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 32, 'n_estimators': 13}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 32, 'n_estimators': 14}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 32, 'n_estimators': 15}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 32, 'n_estimators': 16}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 32, 'n_estimators': 17}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 32, 'n_estimators': 18}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 32, 'n_estimators': 19}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 32, 'n_estimators': 20}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 32, 'n_estimators': 21}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 32, 'n_estimators': 22}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 32, 'n_estimators': 23}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 32, 'n_estimators': 24}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 32, 'n_estimators': 25}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 64, 'n_estimators': 1}, F1 Score: 0.9578282828282829\n",
      "Params: {'max_depth': 64, 'n_estimators': 2}, F1 Score: 0.9501010101010102\n",
      "Params: {'max_depth': 64, 'n_estimators': 3}, F1 Score: 0.9674436674436674\n",
      "Params: {'max_depth': 64, 'n_estimators': 4}, F1 Score: 0.9517676767676768\n",
      "Params: {'max_depth': 64, 'n_estimators': 5}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 64, 'n_estimators': 6}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 64, 'n_estimators': 7}, F1 Score: 0.9664335664335664\n",
      "Params: {'max_depth': 64, 'n_estimators': 8}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 64, 'n_estimators': 9}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 64, 'n_estimators': 10}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 64, 'n_estimators': 11}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 64, 'n_estimators': 12}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 64, 'n_estimators': 13}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 64, 'n_estimators': 14}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 64, 'n_estimators': 15}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 64, 'n_estimators': 16}, F1 Score: 0.9572390572390572\n",
      "Params: {'max_depth': 64, 'n_estimators': 17}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 64, 'n_estimators': 18}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 64, 'n_estimators': 19}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 64, 'n_estimators': 20}, F1 Score: 0.9634343434343435\n",
      "Params: {'max_depth': 64, 'n_estimators': 21}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 64, 'n_estimators': 22}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 64, 'n_estimators': 23}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 64, 'n_estimators': 24}, F1 Score: 0.9707070707070707\n",
      "Params: {'max_depth': 64, 'n_estimators': 25}, F1 Score: 0.9707070707070707\n"
     ]
    }
   ],
   "source": [
    "print(cv_results['mean_test_precision_macro'].mean())\n",
    "print(\"Precision score for each parameter combination:\")\n",
    "for params, f1 in zip(cv_results['params'], cv_results['mean_test_precision_macro']):\n",
    "    print(f\"Params: {params}, F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fefecda-d847-4dc7-9594-8f2588dbf7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00565205, 0.00797973, 0.0120378 , 0.01508322, 0.01835294,\n",
       "        0.01855249, 0.01829939, 0.01859813, 0.01893749, 0.021487  ,\n",
       "        0.02226291, 0.02532258, 0.02754288, 0.0280345 , 0.03118148,\n",
       "        0.03577065, 0.04030724, 0.04149871, 0.04366355, 0.04321613,\n",
       "        0.04531288, 0.04964085, 0.05882206, 0.05696735, 0.05479321,\n",
       "        0.00422568, 0.00604043, 0.00804105, 0.01216455, 0.01237602,\n",
       "        0.01535177, 0.01621404, 0.02252932, 0.02126946, 0.02774806,\n",
       "        0.03044782, 0.02717714, 0.03405933, 0.03923893, 0.0344152 ,\n",
       "        0.03789601, 0.03843336, 0.03930044, 0.04460449, 0.04683805,\n",
       "        0.04636574, 0.04779701, 0.04942307, 0.05320973, 0.05483727,\n",
       "        0.00418696, 0.00621004, 0.00801635, 0.01211171, 0.0142715 ,\n",
       "        0.01409154, 0.01764455, 0.02155423, 0.022755  , 0.02557311,\n",
       "        0.02760592, 0.02738047, 0.03052588, 0.03457747, 0.03566251,\n",
       "        0.0375545 , 0.03680258, 0.04038162, 0.0430841 , 0.04403906,\n",
       "        0.05789194, 0.05505023, 0.05115552, 0.05551262, 0.05534015,\n",
       "        0.00398116, 0.00817523, 0.00890775, 0.01151676, 0.01252422,\n",
       "        0.01526504, 0.01614647, 0.01834917, 0.02097969, 0.02259669,\n",
       "        0.02474122, 0.02768888, 0.02912793, 0.03108878, 0.03345919,\n",
       "        0.03597689, 0.03736196, 0.04069443, 0.04177814, 0.04424143,\n",
       "        0.04574647, 0.04810977, 0.05114803, 0.0521862 , 0.05469007,\n",
       "        0.00412226, 0.00610681, 0.00818057, 0.01039624, 0.01264119,\n",
       "        0.0153995 , 0.01663494, 0.01877522, 0.0222116 , 0.02391295,\n",
       "        0.02550378, 0.027385  , 0.0293591 , 0.03159628, 0.03508706,\n",
       "        0.03637385, 0.0389503 , 0.04057293, 0.04250064, 0.05117159,\n",
       "        0.0487082 , 0.04859872, 0.05060363, 0.05337219, 0.05512238,\n",
       "        0.00379424, 0.00588031, 0.00836105, 0.01047387, 0.0122632 ,\n",
       "        0.01479073, 0.01919374, 0.01881418, 0.02089486, 0.02339668,\n",
       "        0.02515697, 0.02737217, 0.03075438, 0.03240275, 0.03343897,\n",
       "        0.03697681, 0.0391355 , 0.04428816, 0.04496522, 0.05004029,\n",
       "        0.05167794, 0.0502634 , 0.05297179, 0.05769496, 0.05691218,\n",
       "        0.00466914, 0.00595999, 0.00832024, 0.01038537, 0.01295614,\n",
       "        0.01455479, 0.02150645, 0.01971869, 0.02773461, 0.02451749,\n",
       "        0.02659369, 0.02815094, 0.03082905, 0.03476152, 0.03417392,\n",
       "        0.03679705, 0.0387073 , 0.04026074, 0.0427834 , 0.04514003,\n",
       "        0.04744158, 0.0508359 , 0.05153894, 0.05408835, 0.04673209]),\n",
       " 'std_fit_time': array([4.82054128e-04, 4.11477110e-04, 2.27637395e-03, 7.17903681e-04,\n",
       "        1.67208580e-03, 7.54674391e-04, 1.35418650e-03, 1.52808117e-03,\n",
       "        1.39131742e-03, 2.61594864e-03, 1.12694424e-03, 1.86434398e-03,\n",
       "        2.30778555e-03, 4.60962563e-04, 5.07715319e-04, 4.64950673e-03,\n",
       "        5.80374858e-03, 4.16095119e-03, 5.22015712e-03, 1.54112033e-03,\n",
       "        2.74249709e-03, 4.37668420e-03, 4.08909631e-03, 4.89324390e-03,\n",
       "        5.14477292e-03, 6.07462344e-04, 3.34240624e-04, 2.35375660e-04,\n",
       "        2.83922203e-03, 7.87552028e-04, 1.25123914e-03, 4.24760711e-04,\n",
       "        2.51695197e-03, 1.02181749e-03, 5.85027026e-03, 6.16058720e-03,\n",
       "        9.48484898e-04, 1.59028604e-03, 3.53259300e-03, 1.59846642e-03,\n",
       "        3.95495235e-03, 4.47853466e-03, 7.13834113e-04, 3.81634501e-03,\n",
       "        4.03759171e-03, 2.60324306e-03, 1.53137690e-03, 8.25070904e-04,\n",
       "        3.45059398e-03, 2.72834628e-03, 4.80619890e-04, 5.13950043e-04,\n",
       "        2.01706007e-04, 1.62301225e-03, 2.04077356e-03, 2.70627559e-04,\n",
       "        1.78144876e-03, 2.31590623e-03, 2.67289466e-03, 2.61953897e-03,\n",
       "        6.63100627e-03, 1.14022588e-03, 1.24005795e-03, 1.45163548e-03,\n",
       "        1.54990159e-03, 2.87963529e-03, 4.84205499e-04, 3.05140196e-03,\n",
       "        2.21607385e-03, 1.16189804e-03, 2.56040744e-02, 7.78294931e-03,\n",
       "        1.23572705e-03, 3.27016504e-03, 2.00364487e-03, 1.93522432e-04,\n",
       "        1.57621250e-03, 9.75349227e-04, 1.73565126e-03, 5.35429924e-04,\n",
       "        1.67241280e-03, 4.64468261e-04, 2.12097147e-04, 3.74898684e-04,\n",
       "        4.57528610e-04, 3.07473326e-04, 1.51565936e-03, 8.76009515e-04,\n",
       "        1.18832795e-04, 3.37281757e-04, 1.92535435e-03, 4.01836153e-04,\n",
       "        2.56440267e-03, 9.12192019e-04, 8.84690258e-04, 2.61044397e-04,\n",
       "        3.14750308e-04, 2.28901218e-03, 3.56563459e-04, 6.63310660e-04,\n",
       "        4.12745710e-04, 1.91248167e-04, 2.29215696e-04, 3.99854414e-04,\n",
       "        4.41817431e-04, 7.38370529e-04, 4.14176814e-04, 6.84298820e-04,\n",
       "        1.63450076e-03, 2.29708296e-03, 5.43903978e-04, 2.69448185e-04,\n",
       "        9.51457989e-04, 9.11300728e-04, 3.29956924e-03, 1.14862986e-03,\n",
       "        8.43244062e-04, 5.42298483e-04, 4.38261564e-04, 1.24427822e-02,\n",
       "        3.79603421e-03, 4.54596410e-04, 4.96428865e-04, 1.22719880e-03,\n",
       "        4.04628487e-04, 1.03835865e-04, 5.48305508e-05, 4.58337191e-04,\n",
       "        7.26258286e-04, 1.70237851e-04, 2.47118087e-04, 5.42302315e-03,\n",
       "        4.46508864e-04, 2.51740423e-04, 5.73716598e-04, 3.21447702e-04,\n",
       "        6.93056710e-04, 2.31660276e-03, 1.90149197e-03, 5.38293364e-04,\n",
       "        1.00657360e-03, 1.68692627e-03, 6.31822490e-03, 2.55050145e-03,\n",
       "        3.86697792e-03, 7.95456325e-03, 1.54845989e-03, 2.65486300e-03,\n",
       "        4.78808312e-03, 3.53697681e-03, 1.55698440e-03, 1.31543030e-04,\n",
       "        4.36360783e-04, 1.75467885e-04, 6.36493681e-04, 1.49226751e-04,\n",
       "        5.59158904e-03, 8.35481208e-04, 1.20475632e-02, 1.86342393e-03,\n",
       "        1.05797456e-03, 7.99952235e-04, 2.43829819e-03, 5.73960072e-03,\n",
       "        4.25568105e-04, 1.24956781e-03, 2.25949850e-04, 5.74729245e-04,\n",
       "        4.60952209e-04, 5.96643130e-04, 5.72243403e-04, 1.40951142e-03,\n",
       "        2.92585236e-04, 7.27568161e-04, 7.38362130e-03]),\n",
       " 'mean_score_time': array([0.00845199, 0.00829091, 0.0092412 , 0.00926938, 0.00817351,\n",
       "        0.00739346, 0.00732822, 0.00606956, 0.0058939 , 0.00617375,\n",
       "        0.00618072, 0.00776467, 0.00667205, 0.00684247, 0.0068059 ,\n",
       "        0.00752325, 0.00783925, 0.00762892, 0.00781412, 0.00723152,\n",
       "        0.0075141 , 0.00987506, 0.00959673, 0.00950065, 0.00838938,\n",
       "        0.00705132, 0.00609455, 0.00633202, 0.00747108, 0.00682888,\n",
       "        0.00695176, 0.00643821, 0.00887671, 0.00705581, 0.00853596,\n",
       "        0.00907903, 0.00795031, 0.00991874, 0.00847235, 0.006951  ,\n",
       "        0.00730815, 0.00727649, 0.00763154, 0.00832019, 0.00756202,\n",
       "        0.00770183, 0.00783501, 0.00838027, 0.00776105, 0.0099143 ,\n",
       "        0.007023  , 0.00658436, 0.00635905, 0.0076642 , 0.00781331,\n",
       "        0.00632949, 0.0066771 , 0.00726132, 0.00669217, 0.00829344,\n",
       "        0.00717902, 0.00716043, 0.00706644, 0.00825553, 0.00797815,\n",
       "        0.00742035, 0.00729165, 0.00703397, 0.00744495, 0.00769205,\n",
       "        0.00780807, 0.00747638, 0.00793791, 0.00840693, 0.00802546,\n",
       "        0.00951338, 0.00699153, 0.00625811, 0.00668411, 0.00629735,\n",
       "        0.00689569, 0.00676088, 0.00672364, 0.00677681, 0.00851188,\n",
       "        0.0067698 , 0.00683427, 0.00749669, 0.0070097 , 0.00736623,\n",
       "        0.00739207, 0.00706167, 0.00744262, 0.00756764, 0.00751324,\n",
       "        0.00796089, 0.00776138, 0.00933523, 0.00763054, 0.00986452,\n",
       "        0.006214  , 0.0062253 , 0.0064291 , 0.00648093, 0.0064702 ,\n",
       "        0.00645647, 0.00670724, 0.00790873, 0.006635  , 0.00695462,\n",
       "        0.00679131, 0.0069768 , 0.00710945, 0.00774879, 0.00714951,\n",
       "        0.00761433, 0.00727854, 0.00864677, 0.00768294, 0.00736203,\n",
       "        0.00769334, 0.00770812, 0.00783639, 0.00801144, 0.00806522,\n",
       "        0.00601826, 0.00616283, 0.00627599, 0.00626125, 0.00689335,\n",
       "        0.00644417, 0.00667567, 0.00667109, 0.00691977, 0.00699329,\n",
       "        0.00691905, 0.00699167, 0.00725245, 0.00727973, 0.00720234,\n",
       "        0.00733929, 0.00782509, 0.00967441, 0.00803418, 0.00785379,\n",
       "        0.0086369 , 0.00782933, 0.00913763, 0.00821867, 0.00822859,\n",
       "        0.00632305, 0.00624719, 0.00634131, 0.00641932, 0.00658703,\n",
       "        0.00656176, 0.00745897, 0.00695367, 0.0078104 , 0.00740852,\n",
       "        0.00759521, 0.00890284, 0.00706105, 0.00749807, 0.00721512,\n",
       "        0.00745606, 0.00749092, 0.00755453, 0.00749989, 0.00778513,\n",
       "        0.00776477, 0.00807319, 0.00798459, 0.00805302, 0.00510015]),\n",
       " 'std_score_time': array([6.62781616e-04, 6.00768735e-04, 1.22789030e-03, 2.83136276e-04,\n",
       "        3.78156231e-04, 5.22533545e-04, 9.71124260e-04, 3.19094160e-04,\n",
       "        1.56615885e-04, 1.83791042e-04, 1.49564169e-04, 1.73206739e-03,\n",
       "        1.44367803e-04, 2.56077981e-05, 2.08461731e-04, 3.50997607e-04,\n",
       "        5.68718731e-04, 7.43917668e-04, 9.95982494e-04, 8.83397173e-05,\n",
       "        2.93704928e-04, 3.65919579e-03, 1.20114003e-03, 5.49316708e-04,\n",
       "        1.31686243e-03, 2.14348105e-03, 1.85010151e-04, 1.03162989e-04,\n",
       "        1.43095973e-03, 9.05371939e-04, 2.91229144e-04, 1.93616403e-04,\n",
       "        1.37975620e-03, 7.87705275e-04, 1.41571468e-03, 3.75801781e-03,\n",
       "        1.16575044e-03, 1.17391776e-03, 8.36027176e-04, 3.13129620e-04,\n",
       "        5.18206928e-04, 2.14399445e-04, 1.72639484e-04, 1.27921809e-03,\n",
       "        4.00205782e-04, 6.17220114e-04, 5.34993561e-04, 1.06096438e-03,\n",
       "        1.96056943e-04, 3.08272461e-03, 1.67506222e-03, 6.40076466e-04,\n",
       "        7.91275718e-04, 2.90120008e-04, 1.98166123e-03, 1.72223086e-04,\n",
       "        1.65735138e-04, 6.54982788e-04, 1.77270907e-04, 1.17706794e-03,\n",
       "        4.47470199e-04, 2.29589293e-04, 2.04775407e-04, 9.74976513e-04,\n",
       "        1.26085363e-03, 4.07234550e-04, 2.16148164e-04, 1.01279539e-04,\n",
       "        1.19848123e-04, 5.68996464e-04, 9.42882954e-04, 1.13025334e-04,\n",
       "        4.26247160e-04, 9.69174538e-04, 2.99334707e-04, 6.70576526e-03,\n",
       "        1.11400526e-03, 1.75930464e-04, 7.39480556e-04, 6.97278766e-05,\n",
       "        1.08629391e-03, 3.21117005e-04, 1.62504606e-04, 1.97918039e-04,\n",
       "        3.54505586e-03, 1.86566924e-04, 1.31341158e-04, 8.29503467e-04,\n",
       "        1.86800578e-04, 1.80884605e-04, 1.13227451e-04, 7.40743773e-05,\n",
       "        9.59407264e-05, 3.94420951e-04, 5.45717993e-05, 1.56219058e-04,\n",
       "        1.78584116e-04, 3.24031666e-03, 6.35148885e-05, 3.93559472e-03,\n",
       "        1.12362768e-04, 6.72608180e-05, 1.46088354e-04, 1.89428565e-04,\n",
       "        6.70833793e-05, 2.14108996e-04, 2.48239492e-04, 2.00991554e-03,\n",
       "        1.45509138e-04, 2.53532366e-04, 7.08274788e-05, 1.21933835e-04,\n",
       "        1.70435595e-04, 6.13835465e-04, 1.66300772e-04, 2.69792273e-04,\n",
       "        8.24268717e-05, 1.57142813e-03, 2.30194865e-04, 3.68501656e-05,\n",
       "        1.61502950e-04, 1.43056106e-04, 7.34445947e-05, 1.34800996e-04,\n",
       "        1.48144872e-04, 1.33773569e-04, 1.55577387e-04, 1.26497502e-04,\n",
       "        8.73688258e-05, 9.76298893e-04, 3.56645506e-05, 1.19792219e-04,\n",
       "        1.22300375e-04, 2.58726174e-04, 4.41562408e-04, 1.86133285e-04,\n",
       "        1.84171363e-04, 1.59607163e-04, 1.13999150e-04, 4.91529608e-05,\n",
       "        2.04812656e-04, 7.98100621e-04, 4.38240058e-03, 5.15526235e-04,\n",
       "        4.29585409e-04, 1.73986937e-03, 1.25086811e-04, 1.69188812e-03,\n",
       "        5.32576871e-04, 3.98852076e-04, 1.82686104e-04, 1.56752962e-04,\n",
       "        1.93966877e-04, 1.25008807e-04, 4.17015837e-05, 1.09953210e-04,\n",
       "        5.54210260e-04, 3.38860977e-04, 1.77260948e-03, 5.56464379e-04,\n",
       "        9.36657574e-04, 3.74480369e-03, 5.92423683e-05, 1.26305100e-04,\n",
       "        1.79275400e-04, 5.09283962e-04, 6.30297562e-05, 1.84359145e-04,\n",
       "        7.25431224e-05, 1.66494398e-04, 1.26377986e-04, 2.58863102e-04,\n",
       "        2.33358444e-04, 2.41281034e-04, 1.18773091e-03]),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "                    32, 32, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "        fill_value=999999),\n",
       " 'param_n_estimators': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
       "                    17, 18, 19, 20, 21, 22, 23, 24, 25, 1, 2, 3, 4, 5, 6,\n",
       "                    7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "                    21, 22, 23, 24, 25, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                    12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
       "                    17, 18, 19, 20, 21, 22, 23, 24, 25, 1, 2, 3, 4, 5, 6,\n",
       "                    7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "                    21, 22, 23, 24, 25, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                    12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
       "                    17, 18, 19, 20, 21, 22, 23, 24, 25],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "        fill_value=999999),\n",
       " 'params': [{'max_depth': 1, 'n_estimators': 1},\n",
       "  {'max_depth': 1, 'n_estimators': 2},\n",
       "  {'max_depth': 1, 'n_estimators': 3},\n",
       "  {'max_depth': 1, 'n_estimators': 4},\n",
       "  {'max_depth': 1, 'n_estimators': 5},\n",
       "  {'max_depth': 1, 'n_estimators': 6},\n",
       "  {'max_depth': 1, 'n_estimators': 7},\n",
       "  {'max_depth': 1, 'n_estimators': 8},\n",
       "  {'max_depth': 1, 'n_estimators': 9},\n",
       "  {'max_depth': 1, 'n_estimators': 10},\n",
       "  {'max_depth': 1, 'n_estimators': 11},\n",
       "  {'max_depth': 1, 'n_estimators': 12},\n",
       "  {'max_depth': 1, 'n_estimators': 13},\n",
       "  {'max_depth': 1, 'n_estimators': 14},\n",
       "  {'max_depth': 1, 'n_estimators': 15},\n",
       "  {'max_depth': 1, 'n_estimators': 16},\n",
       "  {'max_depth': 1, 'n_estimators': 17},\n",
       "  {'max_depth': 1, 'n_estimators': 18},\n",
       "  {'max_depth': 1, 'n_estimators': 19},\n",
       "  {'max_depth': 1, 'n_estimators': 20},\n",
       "  {'max_depth': 1, 'n_estimators': 21},\n",
       "  {'max_depth': 1, 'n_estimators': 22},\n",
       "  {'max_depth': 1, 'n_estimators': 23},\n",
       "  {'max_depth': 1, 'n_estimators': 24},\n",
       "  {'max_depth': 1, 'n_estimators': 25},\n",
       "  {'max_depth': 2, 'n_estimators': 1},\n",
       "  {'max_depth': 2, 'n_estimators': 2},\n",
       "  {'max_depth': 2, 'n_estimators': 3},\n",
       "  {'max_depth': 2, 'n_estimators': 4},\n",
       "  {'max_depth': 2, 'n_estimators': 5},\n",
       "  {'max_depth': 2, 'n_estimators': 6},\n",
       "  {'max_depth': 2, 'n_estimators': 7},\n",
       "  {'max_depth': 2, 'n_estimators': 8},\n",
       "  {'max_depth': 2, 'n_estimators': 9},\n",
       "  {'max_depth': 2, 'n_estimators': 10},\n",
       "  {'max_depth': 2, 'n_estimators': 11},\n",
       "  {'max_depth': 2, 'n_estimators': 12},\n",
       "  {'max_depth': 2, 'n_estimators': 13},\n",
       "  {'max_depth': 2, 'n_estimators': 14},\n",
       "  {'max_depth': 2, 'n_estimators': 15},\n",
       "  {'max_depth': 2, 'n_estimators': 16},\n",
       "  {'max_depth': 2, 'n_estimators': 17},\n",
       "  {'max_depth': 2, 'n_estimators': 18},\n",
       "  {'max_depth': 2, 'n_estimators': 19},\n",
       "  {'max_depth': 2, 'n_estimators': 20},\n",
       "  {'max_depth': 2, 'n_estimators': 21},\n",
       "  {'max_depth': 2, 'n_estimators': 22},\n",
       "  {'max_depth': 2, 'n_estimators': 23},\n",
       "  {'max_depth': 2, 'n_estimators': 24},\n",
       "  {'max_depth': 2, 'n_estimators': 25},\n",
       "  {'max_depth': 4, 'n_estimators': 1},\n",
       "  {'max_depth': 4, 'n_estimators': 2},\n",
       "  {'max_depth': 4, 'n_estimators': 3},\n",
       "  {'max_depth': 4, 'n_estimators': 4},\n",
       "  {'max_depth': 4, 'n_estimators': 5},\n",
       "  {'max_depth': 4, 'n_estimators': 6},\n",
       "  {'max_depth': 4, 'n_estimators': 7},\n",
       "  {'max_depth': 4, 'n_estimators': 8},\n",
       "  {'max_depth': 4, 'n_estimators': 9},\n",
       "  {'max_depth': 4, 'n_estimators': 10},\n",
       "  {'max_depth': 4, 'n_estimators': 11},\n",
       "  {'max_depth': 4, 'n_estimators': 12},\n",
       "  {'max_depth': 4, 'n_estimators': 13},\n",
       "  {'max_depth': 4, 'n_estimators': 14},\n",
       "  {'max_depth': 4, 'n_estimators': 15},\n",
       "  {'max_depth': 4, 'n_estimators': 16},\n",
       "  {'max_depth': 4, 'n_estimators': 17},\n",
       "  {'max_depth': 4, 'n_estimators': 18},\n",
       "  {'max_depth': 4, 'n_estimators': 19},\n",
       "  {'max_depth': 4, 'n_estimators': 20},\n",
       "  {'max_depth': 4, 'n_estimators': 21},\n",
       "  {'max_depth': 4, 'n_estimators': 22},\n",
       "  {'max_depth': 4, 'n_estimators': 23},\n",
       "  {'max_depth': 4, 'n_estimators': 24},\n",
       "  {'max_depth': 4, 'n_estimators': 25},\n",
       "  {'max_depth': 8, 'n_estimators': 1},\n",
       "  {'max_depth': 8, 'n_estimators': 2},\n",
       "  {'max_depth': 8, 'n_estimators': 3},\n",
       "  {'max_depth': 8, 'n_estimators': 4},\n",
       "  {'max_depth': 8, 'n_estimators': 5},\n",
       "  {'max_depth': 8, 'n_estimators': 6},\n",
       "  {'max_depth': 8, 'n_estimators': 7},\n",
       "  {'max_depth': 8, 'n_estimators': 8},\n",
       "  {'max_depth': 8, 'n_estimators': 9},\n",
       "  {'max_depth': 8, 'n_estimators': 10},\n",
       "  {'max_depth': 8, 'n_estimators': 11},\n",
       "  {'max_depth': 8, 'n_estimators': 12},\n",
       "  {'max_depth': 8, 'n_estimators': 13},\n",
       "  {'max_depth': 8, 'n_estimators': 14},\n",
       "  {'max_depth': 8, 'n_estimators': 15},\n",
       "  {'max_depth': 8, 'n_estimators': 16},\n",
       "  {'max_depth': 8, 'n_estimators': 17},\n",
       "  {'max_depth': 8, 'n_estimators': 18},\n",
       "  {'max_depth': 8, 'n_estimators': 19},\n",
       "  {'max_depth': 8, 'n_estimators': 20},\n",
       "  {'max_depth': 8, 'n_estimators': 21},\n",
       "  {'max_depth': 8, 'n_estimators': 22},\n",
       "  {'max_depth': 8, 'n_estimators': 23},\n",
       "  {'max_depth': 8, 'n_estimators': 24},\n",
       "  {'max_depth': 8, 'n_estimators': 25},\n",
       "  {'max_depth': 16, 'n_estimators': 1},\n",
       "  {'max_depth': 16, 'n_estimators': 2},\n",
       "  {'max_depth': 16, 'n_estimators': 3},\n",
       "  {'max_depth': 16, 'n_estimators': 4},\n",
       "  {'max_depth': 16, 'n_estimators': 5},\n",
       "  {'max_depth': 16, 'n_estimators': 6},\n",
       "  {'max_depth': 16, 'n_estimators': 7},\n",
       "  {'max_depth': 16, 'n_estimators': 8},\n",
       "  {'max_depth': 16, 'n_estimators': 9},\n",
       "  {'max_depth': 16, 'n_estimators': 10},\n",
       "  {'max_depth': 16, 'n_estimators': 11},\n",
       "  {'max_depth': 16, 'n_estimators': 12},\n",
       "  {'max_depth': 16, 'n_estimators': 13},\n",
       "  {'max_depth': 16, 'n_estimators': 14},\n",
       "  {'max_depth': 16, 'n_estimators': 15},\n",
       "  {'max_depth': 16, 'n_estimators': 16},\n",
       "  {'max_depth': 16, 'n_estimators': 17},\n",
       "  {'max_depth': 16, 'n_estimators': 18},\n",
       "  {'max_depth': 16, 'n_estimators': 19},\n",
       "  {'max_depth': 16, 'n_estimators': 20},\n",
       "  {'max_depth': 16, 'n_estimators': 21},\n",
       "  {'max_depth': 16, 'n_estimators': 22},\n",
       "  {'max_depth': 16, 'n_estimators': 23},\n",
       "  {'max_depth': 16, 'n_estimators': 24},\n",
       "  {'max_depth': 16, 'n_estimators': 25},\n",
       "  {'max_depth': 32, 'n_estimators': 1},\n",
       "  {'max_depth': 32, 'n_estimators': 2},\n",
       "  {'max_depth': 32, 'n_estimators': 3},\n",
       "  {'max_depth': 32, 'n_estimators': 4},\n",
       "  {'max_depth': 32, 'n_estimators': 5},\n",
       "  {'max_depth': 32, 'n_estimators': 6},\n",
       "  {'max_depth': 32, 'n_estimators': 7},\n",
       "  {'max_depth': 32, 'n_estimators': 8},\n",
       "  {'max_depth': 32, 'n_estimators': 9},\n",
       "  {'max_depth': 32, 'n_estimators': 10},\n",
       "  {'max_depth': 32, 'n_estimators': 11},\n",
       "  {'max_depth': 32, 'n_estimators': 12},\n",
       "  {'max_depth': 32, 'n_estimators': 13},\n",
       "  {'max_depth': 32, 'n_estimators': 14},\n",
       "  {'max_depth': 32, 'n_estimators': 15},\n",
       "  {'max_depth': 32, 'n_estimators': 16},\n",
       "  {'max_depth': 32, 'n_estimators': 17},\n",
       "  {'max_depth': 32, 'n_estimators': 18},\n",
       "  {'max_depth': 32, 'n_estimators': 19},\n",
       "  {'max_depth': 32, 'n_estimators': 20},\n",
       "  {'max_depth': 32, 'n_estimators': 21},\n",
       "  {'max_depth': 32, 'n_estimators': 22},\n",
       "  {'max_depth': 32, 'n_estimators': 23},\n",
       "  {'max_depth': 32, 'n_estimators': 24},\n",
       "  {'max_depth': 32, 'n_estimators': 25},\n",
       "  {'max_depth': 64, 'n_estimators': 1},\n",
       "  {'max_depth': 64, 'n_estimators': 2},\n",
       "  {'max_depth': 64, 'n_estimators': 3},\n",
       "  {'max_depth': 64, 'n_estimators': 4},\n",
       "  {'max_depth': 64, 'n_estimators': 5},\n",
       "  {'max_depth': 64, 'n_estimators': 6},\n",
       "  {'max_depth': 64, 'n_estimators': 7},\n",
       "  {'max_depth': 64, 'n_estimators': 8},\n",
       "  {'max_depth': 64, 'n_estimators': 9},\n",
       "  {'max_depth': 64, 'n_estimators': 10},\n",
       "  {'max_depth': 64, 'n_estimators': 11},\n",
       "  {'max_depth': 64, 'n_estimators': 12},\n",
       "  {'max_depth': 64, 'n_estimators': 13},\n",
       "  {'max_depth': 64, 'n_estimators': 14},\n",
       "  {'max_depth': 64, 'n_estimators': 15},\n",
       "  {'max_depth': 64, 'n_estimators': 16},\n",
       "  {'max_depth': 64, 'n_estimators': 17},\n",
       "  {'max_depth': 64, 'n_estimators': 18},\n",
       "  {'max_depth': 64, 'n_estimators': 19},\n",
       "  {'max_depth': 64, 'n_estimators': 20},\n",
       "  {'max_depth': 64, 'n_estimators': 21},\n",
       "  {'max_depth': 64, 'n_estimators': 22},\n",
       "  {'max_depth': 64, 'n_estimators': 23},\n",
       "  {'max_depth': 64, 'n_estimators': 24},\n",
       "  {'max_depth': 64, 'n_estimators': 25}],\n",
       " 'split0_test_f1_macro': array([0.55555556, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.96658312, 0.96658312, 0.93333333, 0.93324979, 1.        ,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        1.        , 0.93333333, 1.        , 1.        , 0.96658312,\n",
       "        0.93333333, 0.96658312, 0.93333333, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        1.        , 0.96658312, 1.        , 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        1.        , 0.96658312, 1.        , 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        1.        , 0.96658312, 1.        , 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        1.        , 0.96658312, 1.        , 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        1.        , 0.96658312, 1.        , 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312]),\n",
       " 'split1_test_f1_macro': array([0.53084324, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 1.        , 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312]),\n",
       " 'split2_test_f1_macro': array([0.46962233, 0.46269458, 0.89769821, 0.89769821, 0.89974937,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.89974937, 0.89974937, 0.89974937, 0.89974937, 0.89974937,\n",
       "        0.89974937, 0.89974937, 0.89974937, 0.89974937, 0.89974937,\n",
       "        0.89974937, 0.89974937, 0.89974937, 0.89974937, 0.89974937,\n",
       "        0.89974937, 0.89974937, 0.89974937, 0.89974937, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.86531987, 0.86666667, 0.89769821, 0.86531987, 0.89769821,\n",
       "        0.89769821, 0.89769821, 0.89769821, 0.93265993, 0.89974937,\n",
       "        0.89974937, 0.89974937, 0.89974937, 0.89974937, 0.89974937,\n",
       "        0.89974937, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.86531987, 0.86666667, 0.89769821, 0.86531987, 0.89769821,\n",
       "        0.89769821, 0.89769821, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.89974937, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.86531987, 0.86666667, 0.89769821, 0.86531987, 0.89769821,\n",
       "        0.89769821, 0.89769821, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.89974937, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.86531987, 0.86666667, 0.89769821, 0.86531987, 0.89769821,\n",
       "        0.89769821, 0.89769821, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.89974937, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.86531987, 0.86666667, 0.89769821, 0.86531987, 0.89769821,\n",
       "        0.89769821, 0.89769821, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.89974937, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993]),\n",
       " 'split3_test_f1_macro': array([0.50462963, 0.52435687, 0.96658312, 0.96658312, 0.93265993,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.93121693, 0.93121693,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.89769821, 0.96658312, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.93265993,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.89974937,\n",
       "        0.93265993, 0.93265993, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.89974937, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.93265993, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.89974937, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.93265993, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.89974937, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.93265993, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.89974937, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.93265993, 0.93265993, 0.93265993, 0.93265993, 0.96658312,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312,\n",
       "        0.96658312, 0.93265993, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.89974937, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.96658312, 0.96658312, 0.96658312, 0.96658312, 0.96658312]),\n",
       " 'split4_test_f1_macro': array([0.55555556, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.93265993, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_f1_macro': array([0.52324126, 0.79072691, 0.96617289, 0.96617289, 0.95979849,\n",
       "        0.96648186, 0.96648186, 0.9598319 , 0.93927394, 0.966092  ,\n",
       "        0.96648186, 0.96648186, 0.96648186, 0.96648186, 0.96648186,\n",
       "        0.96648186, 0.96648186, 0.9598319 , 0.9598319 , 0.9598319 ,\n",
       "        0.9598319 , 0.9598319 , 0.9598319 , 0.9598319 , 0.9598319 ,\n",
       "        0.95280614, 0.95993317, 0.95979849, 0.95979849, 0.95311511,\n",
       "        0.94646515, 0.95311511, 0.94646515, 0.95311511, 0.95311511,\n",
       "        0.95311511, 0.95311511, 0.95311511, 0.95311511, 0.95311511,\n",
       "        0.95311511, 0.95311511, 0.95311511, 0.95311511, 0.95969722,\n",
       "        0.95969722, 0.95304726, 0.95304726, 0.95304726, 0.94646515,\n",
       "        0.95291258, 0.94649857, 0.96617289, 0.95301385, 0.95948952,\n",
       "        0.95948952, 0.95948952, 0.95948952, 0.9598319 , 0.95324979,\n",
       "        0.95324979, 0.95324979, 0.95324979, 0.95324979, 0.95324979,\n",
       "        0.95324979, 0.95311511, 0.9598319 , 0.9598319 , 0.9598319 ,\n",
       "        0.9598319 , 0.9598319 , 0.96648186, 0.96648186, 0.96648186,\n",
       "        0.95291258, 0.94649857, 0.95938825, 0.94622921, 0.95948952,\n",
       "        0.95948952, 0.95948952, 0.96648186, 0.96648186, 0.96648186,\n",
       "        0.96648186, 0.95311511, 0.9598319 , 0.9598319 , 0.9598319 ,\n",
       "        0.95311511, 0.9598319 , 0.9598319 , 0.9598319 , 0.9598319 ,\n",
       "        0.96648186, 0.96648186, 0.96648186, 0.96648186, 0.96648186,\n",
       "        0.95291258, 0.94649857, 0.95938825, 0.94622921, 0.95948952,\n",
       "        0.95948952, 0.95948952, 0.96648186, 0.96648186, 0.96648186,\n",
       "        0.96648186, 0.95311511, 0.9598319 , 0.9598319 , 0.9598319 ,\n",
       "        0.95311511, 0.9598319 , 0.9598319 , 0.9598319 , 0.9598319 ,\n",
       "        0.96648186, 0.96648186, 0.96648186, 0.96648186, 0.96648186,\n",
       "        0.95291258, 0.94649857, 0.95938825, 0.94622921, 0.95948952,\n",
       "        0.95948952, 0.95948952, 0.96648186, 0.96648186, 0.96648186,\n",
       "        0.96648186, 0.95311511, 0.9598319 , 0.9598319 , 0.9598319 ,\n",
       "        0.95311511, 0.9598319 , 0.9598319 , 0.9598319 , 0.9598319 ,\n",
       "        0.96648186, 0.96648186, 0.96648186, 0.96648186, 0.96648186,\n",
       "        0.95291258, 0.94649857, 0.95938825, 0.94622921, 0.95948952,\n",
       "        0.95948952, 0.95948952, 0.96648186, 0.96648186, 0.96648186,\n",
       "        0.96648186, 0.95311511, 0.9598319 , 0.9598319 , 0.9598319 ,\n",
       "        0.95311511, 0.9598319 , 0.9598319 , 0.9598319 , 0.9598319 ,\n",
       "        0.96648186, 0.96648186, 0.96648186, 0.96648186, 0.96648186]),\n",
       " 'std_test_f1_macro': array([0.03276461, 0.24375154, 0.03735683, 0.03735683, 0.03904037,\n",
       "        0.02129516, 0.02129516, 0.02508037, 0.01367105, 0.03044247,\n",
       "        0.02129516, 0.02129516, 0.02129516, 0.02129516, 0.02129516,\n",
       "        0.02129516, 0.02129516, 0.02508037, 0.02508037, 0.02508037,\n",
       "        0.02508037, 0.02508037, 0.02508037, 0.02508037, 0.02508037,\n",
       "        0.04581753, 0.03894757, 0.03904037, 0.03904037, 0.03413879,\n",
       "        0.03410603, 0.03413879, 0.03410603, 0.03413879, 0.03413879,\n",
       "        0.03413879, 0.03413879, 0.03413879, 0.03413879, 0.03413879,\n",
       "        0.03413879, 0.03413879, 0.03413879, 0.03413879, 0.0252237 ,\n",
       "        0.0252237 , 0.02686151, 0.02686151, 0.02686151, 0.03410603,\n",
       "        0.05040632, 0.04524118, 0.03735683, 0.04571719, 0.03349693,\n",
       "        0.03349693, 0.03349693, 0.03349693, 0.02508037, 0.03405906,\n",
       "        0.03405906, 0.03405906, 0.03405906, 0.03405906, 0.03405906,\n",
       "        0.03405906, 0.03413879, 0.02508037, 0.02508037, 0.02508037,\n",
       "        0.02508037, 0.02508037, 0.02129516, 0.02129516, 0.02129516,\n",
       "        0.05040632, 0.04524118, 0.03967483, 0.04571719, 0.03349693,\n",
       "        0.03349693, 0.03349693, 0.02129516, 0.02129516, 0.02129516,\n",
       "        0.02129516, 0.03413879, 0.02508037, 0.02508037, 0.02508037,\n",
       "        0.03413879, 0.02508037, 0.02508037, 0.02508037, 0.02508037,\n",
       "        0.02129516, 0.02129516, 0.02129516, 0.02129516, 0.02129516,\n",
       "        0.05040632, 0.04524118, 0.03967483, 0.04571719, 0.03349693,\n",
       "        0.03349693, 0.03349693, 0.02129516, 0.02129516, 0.02129516,\n",
       "        0.02129516, 0.03413879, 0.02508037, 0.02508037, 0.02508037,\n",
       "        0.03413879, 0.02508037, 0.02508037, 0.02508037, 0.02508037,\n",
       "        0.02129516, 0.02129516, 0.02129516, 0.02129516, 0.02129516,\n",
       "        0.05040632, 0.04524118, 0.03967483, 0.04571719, 0.03349693,\n",
       "        0.03349693, 0.03349693, 0.02129516, 0.02129516, 0.02129516,\n",
       "        0.02129516, 0.03413879, 0.02508037, 0.02508037, 0.02508037,\n",
       "        0.03413879, 0.02508037, 0.02508037, 0.02508037, 0.02508037,\n",
       "        0.02129516, 0.02129516, 0.02129516, 0.02129516, 0.02129516,\n",
       "        0.05040632, 0.04524118, 0.03967483, 0.04571719, 0.03349693,\n",
       "        0.03349693, 0.03349693, 0.02129516, 0.02129516, 0.02129516,\n",
       "        0.02129516, 0.03413879, 0.02508037, 0.02508037, 0.02508037,\n",
       "        0.03413879, 0.02508037, 0.02508037, 0.02508037, 0.02508037,\n",
       "        0.02129516, 0.02129516, 0.02129516, 0.02129516, 0.02129516]),\n",
       " 'rank_test_f1_macro': array([175, 174,  49,  49,  97,   1,   1,  54, 173,  52,   1,   1,   1,\n",
       "          1,   1,   1,   1,  54,  54,  54,  54,  54,  54,  54,  54, 160,\n",
       "         53,  97,  97, 129, 166, 129, 166, 129, 129, 129, 129, 129, 129,\n",
       "        129, 129, 129, 129, 129, 100, 100, 151, 151, 151, 166, 155, 161,\n",
       "         49, 154, 102, 102, 102, 102,  54, 122, 122, 122, 122, 122, 122,\n",
       "        122, 129,  54,  54,  54,  54,  54,   1,   1,   1, 155, 161, 118,\n",
       "        169, 102, 102, 102,   1,   1,   1,   1, 129,  54,  54,  54, 129,\n",
       "         54,  54,  54,  54,   1,   1,   1,   1,   1, 155, 161, 118, 169,\n",
       "        102, 102, 102,   1,   1,   1,   1, 129,  54,  54,  54, 129,  54,\n",
       "         54,  54,  54,   1,   1,   1,   1,   1, 155, 161, 118, 169, 102,\n",
       "        102, 102,   1,   1,   1,   1, 129,  54,  54,  54, 129,  54,  54,\n",
       "         54,  54,   1,   1,   1,   1,   1, 155, 161, 118, 169, 102, 102,\n",
       "        102,   1,   1,   1,   1, 129,  54,  54,  54, 129,  54,  54,  54,\n",
       "         54,   1,   1,   1,   1,   1], dtype=int32),\n",
       " 'split0_test_precision_macro': array([0.5       , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.96969697, 0.96969697, 0.93333333, 0.93636364, 1.        ,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        1.        , 0.93333333, 1.        , 1.        , 0.96969697,\n",
       "        0.93333333, 0.96969697, 0.93333333, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        1.        , 0.96969697, 1.        , 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        1.        , 0.96969697, 1.        , 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        1.        , 0.96969697, 1.        , 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        1.        , 0.96969697, 1.        , 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        1.        , 0.96969697, 1.        , 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697]),\n",
       " 'split1_test_precision_macro': array([0.49206349, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 1.        , 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697]),\n",
       " 'split2_test_precision_macro': array([0.41307815, 0.39366516, 0.92307692, 0.92307692, 0.9023569 ,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.9023569 , 0.9023569 , 0.9023569 , 0.9023569 , 0.9023569 ,\n",
       "        0.9023569 , 0.9023569 , 0.9023569 , 0.9023569 , 0.9023569 ,\n",
       "        0.9023569 , 0.9023569 , 0.9023569 , 0.9023569 , 0.9023569 ,\n",
       "        0.9023569 , 0.9023569 , 0.9023569 , 0.9023569 , 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.875     , 0.86666667, 0.92307692, 0.875     , 0.92307692,\n",
       "        0.92307692, 0.92307692, 0.92307692, 0.94444444, 0.9023569 ,\n",
       "        0.9023569 , 0.9023569 , 0.9023569 , 0.9023569 , 0.9023569 ,\n",
       "        0.9023569 , 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.875     , 0.86666667, 0.92307692, 0.875     , 0.92307692,\n",
       "        0.92307692, 0.92307692, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.9023569 , 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.875     , 0.86666667, 0.92307692, 0.875     , 0.92307692,\n",
       "        0.92307692, 0.92307692, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.9023569 , 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.875     , 0.86666667, 0.92307692, 0.875     , 0.92307692,\n",
       "        0.92307692, 0.92307692, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.9023569 , 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.875     , 0.86666667, 0.92307692, 0.875     , 0.92307692,\n",
       "        0.92307692, 0.92307692, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.9023569 , 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444]),\n",
       " 'split3_test_precision_macro': array([0.48484848, 0.46092504, 0.96969697, 0.96969697, 0.94444444,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.93939394, 0.93939394,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.92307692, 0.96969697, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.9023569 ,\n",
       "        0.94444444, 0.94444444, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.9023569 , 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.93333333, 0.93333333, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.94444444, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.9023569 , 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.94444444, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.9023569 , 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.94444444, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.9023569 , 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.96969697,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697,\n",
       "        0.96969697, 0.94444444, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.9023569 , 0.93333333, 0.93333333, 0.93333333, 0.93333333,\n",
       "        0.96969697, 0.96969697, 0.96969697, 0.96969697, 0.96969697]),\n",
       " 'split4_test_precision_macro': array([0.5       , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.94444444, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_precision_macro': array([0.47799803, 0.76485743, 0.97249417, 0.97249417, 0.96329966,\n",
       "        0.97070707, 0.97070707, 0.96343434, 0.94686869, 0.97070707,\n",
       "        0.97070707, 0.97070707, 0.97070707, 0.97070707, 0.97070707,\n",
       "        0.97070707, 0.97070707, 0.96343434, 0.96343434, 0.96343434,\n",
       "        0.96343434, 0.96343434, 0.96343434, 0.96343434, 0.96343434,\n",
       "        0.95902616, 0.96107744, 0.96329966, 0.96329966, 0.95723906,\n",
       "        0.94996633, 0.95723906, 0.94996633, 0.95723906, 0.95723906,\n",
       "        0.95723906, 0.95723906, 0.95723906, 0.95723906, 0.95723906,\n",
       "        0.95723906, 0.95723906, 0.95723906, 0.95723906, 0.96565657,\n",
       "        0.96565657, 0.95838384, 0.95838384, 0.95838384, 0.94996633,\n",
       "        0.95782828, 0.95010101, 0.97249417, 0.95681818, 0.96643357,\n",
       "        0.96643357, 0.96643357, 0.96643357, 0.96343434, 0.95501684,\n",
       "        0.95501684, 0.95501684, 0.95501684, 0.95501684, 0.95501684,\n",
       "        0.95501684, 0.95723906, 0.96343434, 0.96343434, 0.96343434,\n",
       "        0.96343434, 0.96343434, 0.97070707, 0.97070707, 0.97070707,\n",
       "        0.95782828, 0.95010101, 0.96744367, 0.95176768, 0.96643357,\n",
       "        0.96643357, 0.96643357, 0.97070707, 0.97070707, 0.97070707,\n",
       "        0.97070707, 0.95723906, 0.96343434, 0.96343434, 0.96343434,\n",
       "        0.95723906, 0.96343434, 0.96343434, 0.96343434, 0.96343434,\n",
       "        0.97070707, 0.97070707, 0.97070707, 0.97070707, 0.97070707,\n",
       "        0.95782828, 0.95010101, 0.96744367, 0.95176768, 0.96643357,\n",
       "        0.96643357, 0.96643357, 0.97070707, 0.97070707, 0.97070707,\n",
       "        0.97070707, 0.95723906, 0.96343434, 0.96343434, 0.96343434,\n",
       "        0.95723906, 0.96343434, 0.96343434, 0.96343434, 0.96343434,\n",
       "        0.97070707, 0.97070707, 0.97070707, 0.97070707, 0.97070707,\n",
       "        0.95782828, 0.95010101, 0.96744367, 0.95176768, 0.96643357,\n",
       "        0.96643357, 0.96643357, 0.97070707, 0.97070707, 0.97070707,\n",
       "        0.97070707, 0.95723906, 0.96343434, 0.96343434, 0.96343434,\n",
       "        0.95723906, 0.96343434, 0.96343434, 0.96343434, 0.96343434,\n",
       "        0.97070707, 0.97070707, 0.97070707, 0.97070707, 0.97070707,\n",
       "        0.95782828, 0.95010101, 0.96744367, 0.95176768, 0.96643357,\n",
       "        0.96643357, 0.96643357, 0.97070707, 0.97070707, 0.97070707,\n",
       "        0.97070707, 0.95723906, 0.96343434, 0.96343434, 0.96343434,\n",
       "        0.95723906, 0.96343434, 0.96343434, 0.96343434, 0.96343434,\n",
       "        0.97070707, 0.97070707, 0.97070707, 0.97070707, 0.97070707]),\n",
       " 'std_test_precision_macro': array([0.03294702, 0.27665932, 0.02818104, 0.02818104, 0.03688982,\n",
       "        0.01761171, 0.01761171, 0.02316107, 0.01182466, 0.02602848,\n",
       "        0.01761171, 0.01761171, 0.01761171, 0.01761171, 0.01761171,\n",
       "        0.01761171, 0.01761171, 0.02316107, 0.02316107, 0.02316107,\n",
       "        0.02316107, 0.02316107, 0.02316107, 0.02316107, 0.02316107,\n",
       "        0.03993828, 0.03826765, 0.03688982, 0.03688982, 0.03260261,\n",
       "        0.033065  , 0.03260261, 0.033065  , 0.03260261, 0.03260261,\n",
       "        0.03260261, 0.03260261, 0.03260261, 0.03260261, 0.03260261,\n",
       "        0.03260261, 0.03260261, 0.03260261, 0.03260261, 0.02055252,\n",
       "        0.02055252, 0.02398347, 0.02398347, 0.02398347, 0.033065  ,\n",
       "        0.04634096, 0.04527957, 0.02818104, 0.04255931, 0.02465138,\n",
       "        0.02465138, 0.02465138, 0.02465138, 0.02316107, 0.03375719,\n",
       "        0.03375719, 0.03375719, 0.03375719, 0.03375719, 0.03375719,\n",
       "        0.03375719, 0.03260261, 0.02316107, 0.02316107, 0.02316107,\n",
       "        0.02316107, 0.02316107, 0.01761171, 0.01761171, 0.01761171,\n",
       "        0.04634096, 0.04527957, 0.03040487, 0.04222838, 0.02465138,\n",
       "        0.02465138, 0.02465138, 0.01761171, 0.01761171, 0.01761171,\n",
       "        0.01761171, 0.03260261, 0.02316107, 0.02316107, 0.02316107,\n",
       "        0.03260261, 0.02316107, 0.02316107, 0.02316107, 0.02316107,\n",
       "        0.01761171, 0.01761171, 0.01761171, 0.01761171, 0.01761171,\n",
       "        0.04634096, 0.04527957, 0.03040487, 0.04222838, 0.02465138,\n",
       "        0.02465138, 0.02465138, 0.01761171, 0.01761171, 0.01761171,\n",
       "        0.01761171, 0.03260261, 0.02316107, 0.02316107, 0.02316107,\n",
       "        0.03260261, 0.02316107, 0.02316107, 0.02316107, 0.02316107,\n",
       "        0.01761171, 0.01761171, 0.01761171, 0.01761171, 0.01761171,\n",
       "        0.04634096, 0.04527957, 0.03040487, 0.04222838, 0.02465138,\n",
       "        0.02465138, 0.02465138, 0.01761171, 0.01761171, 0.01761171,\n",
       "        0.01761171, 0.03260261, 0.02316107, 0.02316107, 0.02316107,\n",
       "        0.03260261, 0.02316107, 0.02316107, 0.02316107, 0.02316107,\n",
       "        0.01761171, 0.01761171, 0.01761171, 0.01761171, 0.01761171,\n",
       "        0.04634096, 0.04527957, 0.03040487, 0.04222838, 0.02465138,\n",
       "        0.02465138, 0.02465138, 0.01761171, 0.01761171, 0.01761171,\n",
       "        0.01761171, 0.03260261, 0.02316107, 0.02316107, 0.02316107,\n",
       "        0.03260261, 0.02316107, 0.02316107, 0.02316107, 0.02316107,\n",
       "        0.01761171, 0.01761171, 0.01761171, 0.01761171, 0.01761171]),\n",
       " 'rank_test_precision_macro': array([175, 174,   1,   1, 118,   4,   4,  75, 173,   4,   4,   4,   4,\n",
       "          4,   4,   4,   4,  75,  75,  75,  75,  75,  75,  75,  75, 122,\n",
       "        121, 118, 118, 131, 170, 131, 170, 131, 131, 131, 131, 131, 131,\n",
       "        131, 131, 131, 131, 131,  73,  73, 123, 123, 123, 170, 126, 165,\n",
       "          1, 153,  57,  57,  57,  57,  75, 154, 154, 154, 154, 154, 154,\n",
       "        154, 131,  75,  75,  75,  75,  75,   4,   4,   4, 126, 165,  53,\n",
       "        161,  57,  57,  57,   4,   4,   4,   4, 131,  75,  75,  75, 131,\n",
       "         75,  75,  75,  75,   4,   4,   4,   4,   4, 126, 165,  53, 161,\n",
       "         57,  57,  57,   4,   4,   4,   4, 131,  75,  75,  75, 131,  75,\n",
       "         75,  75,  75,   4,   4,   4,   4,   4, 126, 165,  53, 161,  57,\n",
       "         57,  57,   4,   4,   4,   4, 131,  75,  75,  75, 131,  75,  75,\n",
       "         75,  75,   4,   4,   4,   4,   4, 126, 165,  53, 161,  57,  57,\n",
       "         57,   4,   4,   4,   4, 131,  75,  75,  75, 131,  75,  75,  75,\n",
       "         75,   4,   4,   4,   4,   4], dtype=int32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b80849ab-616c-4a7b-b3b9-9b641e662437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configuration: {'max_depth': 1, 'n_estimators': 3}\n",
      "Best Precision Score: 0.9724941724941726\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Configuration:\", mod.best_params_)\n",
    "print(\"Best Precision Score:\", mod.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40556772-1ffc-4818-a540-e74a3c03ca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 175 candidates, totalling 1750 fits\n",
      "Best Configuration: {'max_depth': 8, 'n_estimators': 3}\n",
      "Best Precision Score: 0.9722222222222223\n"
     ]
    }
   ],
   "source": [
    "start4 = time.time()\n",
    "mod2 = GridSearchCV(rf, parameters, cv = 10, scoring = scoring2, refit='precision_macro', verbose = 1, n_jobs = -1)\n",
    "mod2.fit(X,y)\n",
    "end4 = time.time()\n",
    "cv_results2 = mod2.cv_results_\n",
    "print(\"Best Configuration:\", mod2.best_params_)\n",
    "print(\"Best Precision Score:\", mod2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c5324f-a2da-409a-a018-fcc440f40ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for cv = 5:  5.7123799324035645\n",
      "Time for cv = 10:  8.953128576278687\n"
     ]
    }
   ],
   "source": [
    "print(\"Time for cv = 5: \", end3 - start3)\n",
    "print(\"Time for cv = 10: \", end4 - start4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b464118f-2e0b-4278-a4a7-ed68bab91536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "/home/maciejrudy/conda/envs/pandas130/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "diabetes = load_diabetes()\n",
    "X3 = diabetes.data\n",
    "y3 = diabetes.target\n",
    "kn3 = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "scoring3 = {\n",
    "    'R2': make_scorer(r2_score),\n",
    "    'mean_absolute_error': make_scorer(mean_absolute_error)\n",
    "}\n",
    "\n",
    "start3 = time.time()\n",
    "score3 = cross_validate(kn3, X3, y3, n_jobs = 2, verbose = 5, cv = 5, scoring = scoring3, return_train_score=True)\n",
    "end3 = time.time()\n",
    "time3 = end3 - start3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daef35f-ab0a-4573-8c9e-e4cb05a3ff76",
   "metadata": {},
   "source": [
    "So StratifiedKFold will try to keep that ratio in each fold. Now you have specified 10 folds (n_splits). So that means in a single fold, for class 'y' to maintain the ratio, at least 2 / 10 = 0.2 members. But we cannot give less than 1 member (sample) so that's why its throwing an error there.\n",
    "\n",
    "If instead of n_splits=10, you have set n_splits=2, then it would have worked, because than the number of members for 'y' will be 2 / 2 = 1. For n_splits = 10 to work correctly, you need to have atleast 10 samples for each of your classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5db5e4f1-351c-48d0-ab97-e9605b00a51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_splits=10 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start4 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m score4 \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkn3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscoring3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m end4 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m time4 \u001b[38;5;241m=\u001b[39m end4 \u001b[38;5;241m-\u001b[39m start4\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/joblib/parallel.py:1469\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1466\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1469\u001b[0m     islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1471\u001b[0m     \u001b[38;5;66;03m# Handle the fact that the generator of task raised an\u001b[39;00m\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;66;03m# exception. As this part of the code can be executed in\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;66;03m# a thread internal to the backend, register a task with\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m     \u001b[38;5;66;03m# an error that will be raised in the user's thread.\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39m__context__, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1476\u001b[0m         \u001b[38;5;66;03m# Suppress the cause of the exception if it is\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m         \u001b[38;5;66;03m# queue.Empty to avoid cluttered traceback. Only do it\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m         \u001b[38;5;66;03m# if the __context__ is really empty to avoid messing\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m         \u001b[38;5;66;03m# with causes of the original error.\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/sklearn/utils/parallel.py:70\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m---> 70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m    426\u001b[0m         X,\n\u001b[1;32m    427\u001b[0m         y,\n\u001b[1;32m    428\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    429\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    430\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    431\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    432\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    433\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    434\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    435\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    436\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    437\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    438\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    439\u001b[0m     )\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    441\u001b[0m )\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/sklearn/model_selection/_split.py:416\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         (\n\u001b[1;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    414\u001b[0m     )\n\u001b[0;32m--> 416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/sklearn/model_selection/_split.py:147\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    145\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m    146\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[1;32m    148\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[1;32m    149\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/sklearn/model_selection/_split.py:809\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 809\u001b[0m     test_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m test_folds \u001b[38;5;241m==\u001b[39m i\n",
      "File \u001b[0;32m~/conda/envs/pandas130/lib/python3.9/site-packages/sklearn/model_selection/_split.py:771\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    769\u001b[0m min_groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(y_counts)\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m y_counts):\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    772\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_splits=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m cannot be greater than the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of members in each class.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits)\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m min_groups:\n\u001b[1;32m    776\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    777\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    778\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m members, which is less than n_splits=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    779\u001b[0m         \u001b[38;5;241m%\u001b[39m (min_groups, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits),\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    781\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: n_splits=10 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "start4 = time.time()\n",
    "score4 = cross_validate(kn3, X3, y3, n_jobs = 2, verbose = 15, cv = 10, scoring = scoring3, return_train_score=True)\n",
    "end4 = time.time()\n",
    "time4 = end4 - start4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1daa0647-3f78-43dc-a856-5cc3761ad545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.00687194, 0.00459909, 0.00384378, 0.0054791 , 0.00352383]), 'score_time': array([0.04230857, 0.02993011, 0.02790642, 0.04150605, 0.02106833]), 'test_R2': array([-0.46851491, -0.30685643, -0.83681986, -0.55930103, -0.42704228]), 'train_R2': array([-0.31080892, -0.21825669, -0.36288554, -0.16903963, -0.39352396]), 'test_mean_absolute_error': array([68.08988764, 69.39325843, 82.36363636, 79.35227273, 74.23863636]), 'train_mean_absolute_error': array([65.04249292, 62.9121813 , 65.48587571, 60.56214689, 66.3700565 ])}\n",
      "Time spent:  0.34302616119384766\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(score3)\n",
    "print(\"Time spent: \", time3)\n",
    "print(y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2366dd74-2632-41de-9882-7aaeab2d0e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_R2 [-0.46851491 -0.30685643 -0.83681986 -0.55930103 -0.42704228]\n",
      "test_R2 -0.5197069019332347\n",
      "test_mean_absolute_error [68.08988764 69.39325843 82.36363636 79.35227273 74.23863636]\n",
      "test_mean_absolute_error 74.68753830439223\n"
     ]
    }
   ],
   "source": [
    "print(\"test_R2\", score3[\"test_R2\"])\n",
    "print(\"test_R2\", score3[\"test_R2\"].mean())\n",
    "\n",
    "print(\"test_mean_absolute_error\", score3[\"test_mean_absolute_error\"])\n",
    "print(\"test_mean_absolute_error\", score3[\"test_mean_absolute_error\"].mean())\n",
    "\n",
    "print(\"Time spent: \", time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c397f-5408-4d9d-a169-e11e635ef8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test_R2\", score4[\"test_R2\"])\n",
    "print(\"test_R2\", score4[\"test_R2\"].mean())\n",
    "\n",
    "print(\"test_mean_absolute_error\", score4[\"test_mean_absolute_error\"])\n",
    "print(\"test_mean_absolute_error\", score4[\"test_mean_absolute_error\"].mean())\n",
    "\n",
    "print(\"Time spent: \", time4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35bd61ca-28ec-45f4-8210-f581a32493ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0c47b49-e687-457c-b636-3852297f0f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciejrudy/conda/envs/pandas130/lib/python3.9/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configuration: {'n_estimators': 42, 'max_depth': 4}\n",
      "Best R^2 Score: 0.43624561695224917\n",
      "Average R^2 Score: 0.40431569846605764\n",
      "R^2 Scores for each parameter combination:\n",
      "Params: {'n_estimators': 42, 'max_depth': 32}, R^2 Score: 0.4181608610324103\n",
      "Params: {'n_estimators': 21, 'max_depth': 16}, R^2 Score: 0.4101437742761461\n",
      "Params: {'n_estimators': 78, 'max_depth': 128}, R^2 Score: 0.4202360274140894\n",
      "Params: {'n_estimators': 30, 'max_depth': 32}, R^2 Score: 0.4123216452922168\n",
      "Params: {'n_estimators': 39, 'max_depth': 256}, R^2 Score: 0.4177378965850468\n",
      "Params: {'n_estimators': 24, 'max_depth': 16}, R^2 Score: 0.4107350989446865\n",
      "Params: {'n_estimators': 12, 'max_depth': 512}, R^2 Score: 0.37738059513564676\n",
      "Params: {'n_estimators': 81, 'max_depth': 1024}, R^2 Score: 0.4207626243416828\n",
      "Params: {'n_estimators': 81, 'max_depth': 16}, R^2 Score: 0.423300384025893\n",
      "Params: {'n_estimators': 33, 'max_depth': 2}, R^2 Score: 0.40314448651182266\n",
      "Params: {'n_estimators': 9, 'max_depth': 128}, R^2 Score: 0.37026317744669224\n",
      "Params: {'n_estimators': 51, 'max_depth': 64}, R^2 Score: 0.41349049473676047\n",
      "Params: {'n_estimators': 48, 'max_depth': 128}, R^2 Score: 0.41369308997155063\n",
      "Params: {'n_estimators': 18, 'max_depth': 64}, R^2 Score: 0.3983054320093794\n",
      "Params: {'n_estimators': 27, 'max_depth': 1024}, R^2 Score: 0.4115247078577623\n",
      "Params: {'n_estimators': 66, 'max_depth': 16}, R^2 Score: 0.42355315805844374\n",
      "Params: {'n_estimators': 75, 'max_depth': 2}, R^2 Score: 0.40665204507410513\n",
      "Params: {'n_estimators': 63, 'max_depth': 512}, R^2 Score: 0.42081221753841247\n",
      "Params: {'n_estimators': 15, 'max_depth': 16}, R^2 Score: 0.39644806659205195\n",
      "Params: {'n_estimators': 15, 'max_depth': 1}, R^2 Score: 0.31179860820183675\n",
      "Params: {'n_estimators': 78, 'max_depth': 1}, R^2 Score: 0.3274790511744821\n",
      "Params: {'n_estimators': 21, 'max_depth': 128}, R^2 Score: 0.40977028681178507\n",
      "Params: {'n_estimators': 51, 'max_depth': 8}, R^2 Score: 0.4131891546732386\n",
      "Params: {'n_estimators': 24, 'max_depth': 64}, R^2 Score: 0.4096543994765972\n",
      "Params: {'n_estimators': 24, 'max_depth': 1024}, R^2 Score: 0.4096543994765972\n",
      "Params: {'n_estimators': 78, 'max_depth': 256}, R^2 Score: 0.4202360274140894\n",
      "Params: {'n_estimators': 45, 'max_depth': 128}, R^2 Score: 0.4194530749729154\n",
      "Params: {'n_estimators': 39, 'max_depth': 1}, R^2 Score: 0.3289419144424191\n",
      "Params: {'n_estimators': 12, 'max_depth': 256}, R^2 Score: 0.37738059513564676\n",
      "Params: {'n_estimators': 81, 'max_depth': 8}, R^2 Score: 0.4219526645240981\n",
      "Params: {'n_estimators': 30, 'max_depth': 256}, R^2 Score: 0.4123216452922168\n",
      "Params: {'n_estimators': 48, 'max_depth': 64}, R^2 Score: 0.41369308997155063\n",
      "Params: {'n_estimators': 27, 'max_depth': 32}, R^2 Score: 0.4115247078577623\n",
      "Params: {'n_estimators': 18, 'max_depth': 256}, R^2 Score: 0.3983054320093794\n",
      "Params: {'n_estimators': 69, 'max_depth': 2}, R^2 Score: 0.40656178804153076\n",
      "Params: {'n_estimators': 57, 'max_depth': 4}, R^2 Score: 0.4331552611514574\n",
      "Params: {'n_estimators': 48, 'max_depth': 256}, R^2 Score: 0.41369308997155063\n",
      "Params: {'n_estimators': 18, 'max_depth': 1024}, R^2 Score: 0.3983054320093794\n",
      "Params: {'n_estimators': 42, 'max_depth': 64}, R^2 Score: 0.4181608610324103\n",
      "Params: {'n_estimators': 39, 'max_depth': 32}, R^2 Score: 0.4177378965850468\n",
      "Params: {'n_estimators': 75, 'max_depth': 64}, R^2 Score: 0.420502701835194\n",
      "Params: {'n_estimators': 15, 'max_depth': 128}, R^2 Score: 0.39121053404963935\n",
      "Params: {'n_estimators': 72, 'max_depth': 16}, R^2 Score: 0.4236934342519539\n",
      "Params: {'n_estimators': 42, 'max_depth': 4}, R^2 Score: 0.43624561695224917\n",
      "Params: {'n_estimators': 15, 'max_depth': 8}, R^2 Score: 0.4013417204330022\n",
      "Params: {'n_estimators': 21, 'max_depth': 512}, R^2 Score: 0.40977028681178507\n",
      "Params: {'n_estimators': 21, 'max_depth': 4}, R^2 Score: 0.4350770947200207\n",
      "Params: {'n_estimators': 72, 'max_depth': 32}, R^2 Score: 0.4203027377816196\n",
      "Params: {'n_estimators': 15, 'max_depth': 2}, R^2 Score: 0.3986157620727865\n",
      "Params: {'n_estimators': 6, 'max_depth': 1}, R^2 Score: 0.3280488425357621\n",
      "Params: {'n_estimators': 66, 'max_depth': 32}, R^2 Score: 0.4201315609223822\n",
      "Params: {'n_estimators': 30, 'max_depth': 8}, R^2 Score: 0.4155619480931496\n",
      "Params: {'n_estimators': 69, 'max_depth': 512}, R^2 Score: 0.42120450315704583\n",
      "Params: {'n_estimators': 63, 'max_depth': 32}, R^2 Score: 0.42081221753841247\n",
      "Params: {'n_estimators': 21, 'max_depth': 64}, R^2 Score: 0.40977028681178507\n",
      "Params: {'n_estimators': 81, 'max_depth': 128}, R^2 Score: 0.4207626243416828\n",
      "Params: {'n_estimators': 60, 'max_depth': 2}, R^2 Score: 0.405756742368943\n",
      "Params: {'n_estimators': 33, 'max_depth': 32}, R^2 Score: 0.41668920208421384\n",
      "Params: {'n_estimators': 15, 'max_depth': 64}, R^2 Score: 0.39121053404963935\n",
      "Params: {'n_estimators': 81, 'max_depth': 4}, R^2 Score: 0.4350490096173429\n",
      "Params: {'n_estimators': 66, 'max_depth': 512}, R^2 Score: 0.4201315609223822\n",
      "Params: {'n_estimators': 57, 'max_depth': 1}, R^2 Score: 0.3295644672725664\n",
      "Params: {'n_estimators': 45, 'max_depth': 32}, R^2 Score: 0.4194530749729154\n",
      "Params: {'n_estimators': 9, 'max_depth': 2}, R^2 Score: 0.40108139526562664\n",
      "Params: {'n_estimators': 15, 'max_depth': 256}, R^2 Score: 0.39121053404963935\n",
      "Params: {'n_estimators': 36, 'max_depth': 1024}, R^2 Score: 0.42034850766128695\n",
      "Params: {'n_estimators': 78, 'max_depth': 8}, R^2 Score: 0.4202512550088322\n",
      "Params: {'n_estimators': 18, 'max_depth': 32}, R^2 Score: 0.3983054320093794\n",
      "Params: {'n_estimators': 78, 'max_depth': 64}, R^2 Score: 0.4202360274140894\n",
      "Params: {'n_estimators': 39, 'max_depth': 8}, R^2 Score: 0.41941144346122955\n",
      "Params: {'n_estimators': 57, 'max_depth': 256}, R^2 Score: 0.41696779715187127\n",
      "Params: {'n_estimators': 42, 'max_depth': 1024}, R^2 Score: 0.4181608610324103\n",
      "Params: {'n_estimators': 15, 'max_depth': 512}, R^2 Score: 0.39121053404963935\n",
      "Params: {'n_estimators': 60, 'max_depth': 16}, R^2 Score: 0.4227014652474191\n",
      "Params: {'n_estimators': 57, 'max_depth': 512}, R^2 Score: 0.41696779715187127\n",
      "Params: {'n_estimators': 57, 'max_depth': 128}, R^2 Score: 0.41696779715187127\n",
      "Params: {'n_estimators': 60, 'max_depth': 8}, R^2 Score: 0.41726177673716097\n",
      "Params: {'n_estimators': 12, 'max_depth': 16}, R^2 Score: 0.3838717689618778\n",
      "Params: {'n_estimators': 12, 'max_depth': 1024}, R^2 Score: 0.37738059513564676\n",
      "Params: {'n_estimators': 9, 'max_depth': 16}, R^2 Score: 0.37117757216810926\n",
      "Params: {'n_estimators': 6, 'max_depth': 4}, R^2 Score: 0.4102199091408073\n",
      "Params: {'n_estimators': 75, 'max_depth': 512}, R^2 Score: 0.420502701835194\n",
      "Params: {'n_estimators': 72, 'max_depth': 1024}, R^2 Score: 0.4203027377816196\n",
      "Params: {'n_estimators': 9, 'max_depth': 1024}, R^2 Score: 0.37026317744669224\n",
      "Params: {'n_estimators': 63, 'max_depth': 256}, R^2 Score: 0.42081221753841247\n",
      "Params: {'n_estimators': 57, 'max_depth': 64}, R^2 Score: 0.41696779715187127\n",
      "Params: {'n_estimators': 81, 'max_depth': 256}, R^2 Score: 0.4207626243416828\n",
      "Params: {'n_estimators': 3, 'max_depth': 64}, R^2 Score: 0.2306816818319816\n",
      "Params: {'n_estimators': 63, 'max_depth': 64}, R^2 Score: 0.42081221753841247\n",
      "Params: {'n_estimators': 63, 'max_depth': 16}, R^2 Score: 0.4238711666148475\n",
      "Params: {'n_estimators': 60, 'max_depth': 32}, R^2 Score: 0.41902794563563406\n",
      "Params: {'n_estimators': 12, 'max_depth': 128}, R^2 Score: 0.37738059513564676\n",
      "Params: {'n_estimators': 45, 'max_depth': 256}, R^2 Score: 0.4194530749729154\n",
      "Params: {'n_estimators': 69, 'max_depth': 64}, R^2 Score: 0.42120450315704583\n",
      "Params: {'n_estimators': 6, 'max_depth': 128}, R^2 Score: 0.32275822862494447\n",
      "Params: {'n_estimators': 78, 'max_depth': 1024}, R^2 Score: 0.4202360274140894\n",
      "Params: {'n_estimators': 54, 'max_depth': 2}, R^2 Score: 0.4056537873480687\n",
      "Params: {'n_estimators': 54, 'max_depth': 512}, R^2 Score: 0.4144168207329148\n",
      "Params: {'n_estimators': 78, 'max_depth': 32}, R^2 Score: 0.4202360274140894\n",
      "Params: {'n_estimators': 57, 'max_depth': 16}, R^2 Score: 0.41995241862365595\n",
      "MAE Scores for each parameter combination:\n",
      "Params: {'n_estimators': 42, 'max_depth': 32}, MAE Score: 47.01815932195146\n",
      "Params: {'n_estimators': 21, 'max_depth': 16}, MAE Score: 47.093599985869346\n",
      "Params: {'n_estimators': 78, 'max_depth': 128}, MAE Score: 47.15253692936277\n",
      "Params: {'n_estimators': 30, 'max_depth': 32}, MAE Score: 47.15988764044944\n",
      "Params: {'n_estimators': 39, 'max_depth': 256}, MAE Score: 47.012456457400276\n",
      "Params: {'n_estimators': 24, 'max_depth': 16}, MAE Score: 47.19944916267256\n",
      "Params: {'n_estimators': 12, 'max_depth': 512}, MAE Score: 48.03612529792306\n",
      "Params: {'n_estimators': 81, 'max_depth': 1024}, MAE Score: 47.12827683829556\n",
      "Params: {'n_estimators': 81, 'max_depth': 16}, MAE Score: 46.96320225153022\n",
      "Params: {'n_estimators': 33, 'max_depth': 2}, MAE Score: 47.74397197748346\n",
      "Params: {'n_estimators': 9, 'max_depth': 128}, MAE Score: 48.38996424923391\n",
      "Params: {'n_estimators': 51, 'max_depth': 64}, MAE Score: 47.31655901379959\n",
      "Params: {'n_estimators': 48, 'max_depth': 128}, MAE Score: 47.32380830779707\n",
      "Params: {'n_estimators': 18, 'max_depth': 64}, MAE Score: 47.621338383838385\n",
      "Params: {'n_estimators': 27, 'max_depth': 1024}, MAE Score: 47.16413573941664\n",
      "Params: {'n_estimators': 66, 'max_depth': 16}, MAE Score: 46.87939647743404\n",
      "Params: {'n_estimators': 75, 'max_depth': 2}, MAE Score: 47.66023365553441\n",
      "Params: {'n_estimators': 63, 'max_depth': 512}, MAE Score: 47.06625889715778\n",
      "Params: {'n_estimators': 15, 'max_depth': 16}, MAE Score: 47.63124725586523\n",
      "Params: {'n_estimators': 15, 'max_depth': 1}, MAE Score: 52.31216079535862\n",
      "Params: {'n_estimators': 78, 'max_depth': 1}, MAE Score: 51.918346570546376\n",
      "Params: {'n_estimators': 21, 'max_depth': 128}, MAE Score: 47.13233741913517\n",
      "Params: {'n_estimators': 51, 'max_depth': 8}, MAE Score: 47.3571497121159\n",
      "Params: {'n_estimators': 24, 'max_depth': 64}, MAE Score: 47.25313032005447\n",
      "Params: {'n_estimators': 24, 'max_depth': 1024}, MAE Score: 47.25313032005447\n",
      "Params: {'n_estimators': 78, 'max_depth': 256}, MAE Score: 47.15253692936277\n",
      "Params: {'n_estimators': 45, 'max_depth': 128}, MAE Score: 46.95917602996254\n",
      "Params: {'n_estimators': 39, 'max_depth': 1}, MAE Score: 51.96076220744762\n",
      "Params: {'n_estimators': 12, 'max_depth': 256}, MAE Score: 48.03612529792306\n",
      "Params: {'n_estimators': 81, 'max_depth': 8}, MAE Score: 47.04202517330302\n",
      "Params: {'n_estimators': 30, 'max_depth': 256}, MAE Score: 47.15988764044944\n",
      "Params: {'n_estimators': 48, 'max_depth': 64}, MAE Score: 47.32380830779707\n",
      "Params: {'n_estimators': 27, 'max_depth': 32}, MAE Score: 47.16413573941664\n",
      "Params: {'n_estimators': 18, 'max_depth': 256}, MAE Score: 47.621338383838385\n",
      "Params: {'n_estimators': 69, 'max_depth': 2}, MAE Score: 47.663777712369324\n",
      "Params: {'n_estimators': 57, 'max_depth': 4}, MAE Score: 46.34137200679668\n",
      "Params: {'n_estimators': 48, 'max_depth': 256}, MAE Score: 47.32380830779707\n",
      "Params: {'n_estimators': 18, 'max_depth': 1024}, MAE Score: 47.621338383838385\n",
      "Params: {'n_estimators': 42, 'max_depth': 64}, MAE Score: 47.01815932195146\n",
      "Params: {'n_estimators': 39, 'max_depth': 32}, MAE Score: 47.012456457400276\n",
      "Params: {'n_estimators': 75, 'max_depth': 64}, MAE Score: 47.056011235955054\n",
      "Params: {'n_estimators': 15, 'max_depth': 128}, MAE Score: 47.737088866189985\n",
      "Params: {'n_estimators': 72, 'max_depth': 16}, MAE Score: 46.89341004406708\n",
      "Params: {'n_estimators': 42, 'max_depth': 4}, MAE Score: 46.18140088699034\n",
      "Params: {'n_estimators': 15, 'max_depth': 8}, MAE Score: 47.73199741104979\n",
      "Params: {'n_estimators': 21, 'max_depth': 512}, MAE Score: 47.13233741913517\n",
      "Params: {'n_estimators': 21, 'max_depth': 4}, MAE Score: 46.28074103317722\n",
      "Params: {'n_estimators': 72, 'max_depth': 32}, MAE Score: 47.11298022358415\n",
      "Params: {'n_estimators': 15, 'max_depth': 2}, MAE Score: 47.898328663752196\n",
      "Params: {'n_estimators': 6, 'max_depth': 1}, MAE Score: 52.044731968656095\n",
      "Params: {'n_estimators': 66, 'max_depth': 32}, MAE Score: 47.106456031200665\n",
      "Params: {'n_estimators': 30, 'max_depth': 8}, MAE Score: 47.212553071024175\n",
      "Params: {'n_estimators': 69, 'max_depth': 512}, MAE Score: 47.13001658006543\n",
      "Params: {'n_estimators': 63, 'max_depth': 32}, MAE Score: 47.06625889715778\n",
      "Params: {'n_estimators': 21, 'max_depth': 64}, MAE Score: 47.13233741913517\n",
      "Params: {'n_estimators': 81, 'max_depth': 128}, MAE Score: 47.12827683829556\n",
      "Params: {'n_estimators': 60, 'max_depth': 2}, MAE Score: 47.66841749403077\n",
      "Params: {'n_estimators': 33, 'max_depth': 32}, MAE Score: 47.069449345343116\n",
      "Params: {'n_estimators': 15, 'max_depth': 64}, MAE Score: 47.737088866189985\n",
      "Params: {'n_estimators': 81, 'max_depth': 4}, MAE Score: 46.2950543328271\n",
      "Params: {'n_estimators': 66, 'max_depth': 512}, MAE Score: 47.106456031200665\n",
      "Params: {'n_estimators': 57, 'max_depth': 1}, MAE Score: 51.90407626144755\n",
      "Params: {'n_estimators': 45, 'max_depth': 32}, MAE Score: 46.95917602996254\n",
      "Params: {'n_estimators': 9, 'max_depth': 2}, MAE Score: 47.864959026286336\n",
      "Params: {'n_estimators': 15, 'max_depth': 256}, MAE Score: 47.737088866189985\n",
      "Params: {'n_estimators': 36, 'max_depth': 1024}, MAE Score: 46.89308392917944\n",
      "Params: {'n_estimators': 78, 'max_depth': 8}, MAE Score: 47.12207157862821\n",
      "Params: {'n_estimators': 18, 'max_depth': 32}, MAE Score: 47.621338383838385\n",
      "Params: {'n_estimators': 78, 'max_depth': 64}, MAE Score: 47.15253692936277\n",
      "Params: {'n_estimators': 39, 'max_depth': 8}, MAE Score: 47.03665366519576\n",
      "Params: {'n_estimators': 57, 'max_depth': 256}, MAE Score: 47.23344219844811\n",
      "Params: {'n_estimators': 42, 'max_depth': 1024}, MAE Score: 47.01815932195146\n",
      "Params: {'n_estimators': 15, 'max_depth': 512}, MAE Score: 47.737088866189985\n",
      "Params: {'n_estimators': 60, 'max_depth': 16}, MAE Score: 46.901034264779724\n",
      "Params: {'n_estimators': 57, 'max_depth': 512}, MAE Score: 47.23344219844811\n",
      "Params: {'n_estimators': 57, 'max_depth': 128}, MAE Score: 47.23344219844811\n",
      "Params: {'n_estimators': 60, 'max_depth': 8}, MAE Score: 47.22930268495296\n",
      "Params: {'n_estimators': 12, 'max_depth': 16}, MAE Score: 47.83746618809821\n",
      "Params: {'n_estimators': 12, 'max_depth': 1024}, MAE Score: 48.03612529792306\n",
      "Params: {'n_estimators': 9, 'max_depth': 16}, MAE Score: 48.46495264757438\n",
      "Params: {'n_estimators': 6, 'max_depth': 4}, MAE Score: 46.80611386846398\n",
      "Params: {'n_estimators': 75, 'max_depth': 512}, MAE Score: 47.056011235955054\n",
      "Params: {'n_estimators': 72, 'max_depth': 1024}, MAE Score: 47.11298022358415\n",
      "Params: {'n_estimators': 9, 'max_depth': 1024}, MAE Score: 48.38996424923391\n",
      "Params: {'n_estimators': 63, 'max_depth': 256}, MAE Score: 47.06625889715778\n",
      "Params: {'n_estimators': 57, 'max_depth': 64}, MAE Score: 47.23344219844811\n",
      "Params: {'n_estimators': 81, 'max_depth': 256}, MAE Score: 47.12827683829556\n",
      "Params: {'n_estimators': 3, 'max_depth': 64}, MAE Score: 52.0500680966973\n",
      "Params: {'n_estimators': 63, 'max_depth': 64}, MAE Score: 47.06625889715778\n",
      "Params: {'n_estimators': 63, 'max_depth': 16}, MAE Score: 46.83405075711359\n",
      "Params: {'n_estimators': 60, 'max_depth': 32}, MAE Score: 47.14865721824991\n",
      "Params: {'n_estimators': 12, 'max_depth': 128}, MAE Score: 48.03612529792306\n",
      "Params: {'n_estimators': 45, 'max_depth': 256}, MAE Score: 46.95917602996254\n",
      "Params: {'n_estimators': 69, 'max_depth': 64}, MAE Score: 47.13001658006543\n",
      "Params: {'n_estimators': 6, 'max_depth': 128}, MAE Score: 49.31763278855975\n",
      "Params: {'n_estimators': 78, 'max_depth': 1024}, MAE Score: 47.15253692936277\n",
      "Params: {'n_estimators': 54, 'max_depth': 2}, MAE Score: 47.76063333986506\n",
      "Params: {'n_estimators': 54, 'max_depth': 512}, MAE Score: 47.31652479854727\n",
      "Params: {'n_estimators': 78, 'max_depth': 32}, MAE Score: 47.15253692936277\n",
      "Params: {'n_estimators': 57, 'max_depth': 16}, MAE Score: 47.00734843766178\n",
      "Average MAE: 47.57849017687535\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciejrudy/conda/envs/pandas130/lib/python3.9/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configuration with 10 folds: {'n_estimators': 78, 'max_depth': 4}\n",
      "Best R^2 Score with 10 folds: 0.41746405674263726\n",
      "Training time: 20.21255874633789 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load diabetes dataset\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Define Random Forest model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define parameter grid\n",
    "param_distributions = {\n",
    "    'max_depth': [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n",
    "    'n_estimators': list(range(3, 82, 3))\n",
    "}\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'r2': make_scorer(r2_score),\n",
    "    'mae': make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "}\n",
    "\n",
    "# A: Perform RandomizedSearchCV with 100 combinations\n",
    "start_time = time.time()\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions, n_iter=100, cv=5, scoring=scoring, refit='r2', n_jobs=-1, verbose=1\n",
    ")\n",
    "random_search.fit(X, y)\n",
    "end_time = time.time()\n",
    "\n",
    "# B: Best configuration\n",
    "print(\"Best Configuration:\", random_search.best_params_)\n",
    "print(\"Best R^2 Score:\", random_search.best_score_)\n",
    "\n",
    "# C: Average R^2 score\n",
    "cv_results = random_search.cv_results_\n",
    "r2_scores = cv_results['mean_test_r2']\n",
    "print(\"Average R^2 Score:\", np.mean(r2_scores))\n",
    "\n",
    "# D: R^2 score for each fold\n",
    "print(\"R^2 Scores for each parameter combination:\")\n",
    "for params, r2 in zip(cv_results['params'], r2_scores):\n",
    "    print(f\"Params: {params}, R^2 Score: {r2}\")\n",
    "\n",
    "# E: MAE for each fold\n",
    "mae_scores = -cv_results['mean_test_mae']  # Negative because MAE was negated for scoring\n",
    "print(\"MAE Scores for each parameter combination:\")\n",
    "for params, mae in zip(cv_results['params'], mae_scores):\n",
    "    print(f\"Params: {params}, MAE Score: {mae}\")\n",
    "print(\"Average MAE:\", np.mean(mae_scores))\n",
    "\n",
    "# F: 10-Fold Cross-Validation\n",
    "random_search_10 = RandomizedSearchCV(\n",
    "    rf, param_distributions, n_iter=200, cv=10, scoring=scoring, refit='r2', n_jobs=-1, verbose=1\n",
    ")\n",
    "random_search_10.fit(X, y)\n",
    "print(\"Best Configuration with 10 folds:\", random_search_10.best_params_)\n",
    "print(\"Best R^2 Score with 10 folds:\", random_search_10.best_score_)\n",
    "\n",
    "# G: Training time\n",
    "print(\"Training time:\", end_time - start_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35cf153-3b2b-4bd4-9213-9239f4046466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
